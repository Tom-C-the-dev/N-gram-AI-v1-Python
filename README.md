# N-gram-AI-v1-Python
All versions of my N-gram model in python. Mainly made to write a Shakespearean sonnet.
v1 - proof of concept; doesnt have temperature or word context
v2 - added word context but is liable to a degeneracy loop
v3 - added temperature and updated word context; fully working

for use:
'source' - file that it trains off of'
'n' - amount of word context (1 is 2  words of context)
'temperature' - how random the generation is (0 being not random, 1 being mildly random etc)
'word_count' - amount of words it writes (roughly)
